{"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#The 1st iteration of the Soybean detection & color analysis Prototype\n#Worked on by: Fubin & Bayler","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Imports\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nfrom collections import Counter\nfrom skimage.color import rgb2lab, deltaE_cie76\nimport os\n\n%matplotlib inline\n\n#Defining function for getting an image properly\ndef get_image(image_path):\n    image = cv2.imread(image_path)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image\n\n#Defining funciton for convert from RGB to HEX\ndef RGB2HEX(color):\n    return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))\n\n# load image as grayscale\nimg = cv2.imread('Cropped.jpg')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# threshold input image using otsu thresholding as mask and refine with morphology\nblur = cv2.GaussianBlur(gray,(5,5),0)\nret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU) \nkernel = np.ones((9,9), np.uint8)\nmask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\nmask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n\n# put thresh into \nresult = img.copy()\nresult = cv2.cvtColor(result, cv2.COLOR_BGR2RGBA)\nresult[:, :, 3] = mask\n\n#Beginning of color analysis section\n\n#Resizing & reshaping the mask\nmodified_image = cv2.resize(result, (600, 400), interpolation = cv2.INTER_AREA)\nmodified_image = modified_image.reshape(modified_image.shape[0]*modified_image.shape[1], 3)\n\n#Adjustments for available colors for analysis\nclf = KMeans(n_clusters = 10) #number of colors here\nlabels = clf.fit_predict(modified_image)\ncounts = Counter(labels)\n\n#Retrieve ordered colors by iterating through the keys\ncenter_colors = clf.cluster_centers_\nordered_colors = [center_colors[i] for i in counts.keys()]\nhex_colors = [RGB2HEX(ordered_colors[i]) for i in counts.keys()]\nrgb_colors = [ordered_colors[i] for i in counts.keys()]\n\n#Displaying the pie chart\nif (True) :\n    plt.figure(figsize = (8, 6))\n    plt.pie(counts.values(), labels = hex_colors, colors = hex_colors)\nrgb_colors","metadata":{"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-45f58782c0e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#Resizing & reshaping the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodified_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodified_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodified_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#Adjustments for available colors for analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 960000 into shape (240000,3)"],"ename":"ValueError","evalue":"cannot reshape array of size 960000 into shape (240000,3)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}